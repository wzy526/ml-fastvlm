{
  "model_config": "LLaVA_FastViTHD_0.5B_Stage2",
  "vision_encoder": "fastvithd",
  "llm": "Qwen2",
  "input_resolution": "1024x1024",
  "visual_tokens": 256,
  "model_size": "0.5B",
  "stage": 2,
  "model_path": "./checkpoints/llava-fastvithd_0.5b_stage2",
  "data_path": "/root/gqa_opendatalab/testdev_balanced_questions.json",
  "warmup_samples": 100,
  "total_samples": 12478,
  "accumulated_latency_ms": 1126408.625,
  "avg_ttft_ms": 90.27156795960892,
  "calculation_method": "dist.all_reduce(sum)",
  "world_size": 1,
  "timestamp": "2025-08-14 18:10:45"
}